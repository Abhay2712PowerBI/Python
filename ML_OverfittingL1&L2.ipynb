{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85158241-5ece-481e-b033-29d122702dfe",
   "metadata": {},
   "source": [
    "## ML models using overfitting regularization L1/L2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e48343f4-2c06-4593-ab12-9ca9d090cac3",
   "metadata": {},
   "source": [
    "Overfitting happens when a model learns the noise and random fluctuations in the training data instead of the underlying patterns. One of the standard ways to address this is regularization, especially L1 (Lasso) and L2 (Ridge) penalties."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e917faff-7dc0-4d3a-a088-e2833216b390",
   "metadata": {},
   "source": [
    "L1 Regularization (Lasso): Shrinks some weights to exactly zero, performing feature selection.\n",
    "L2 Regularization (Ridge):Shrinks weights toward zero smoothly, keeping all features but reducing their impact.\n",
    "ElasticNet combines both: L1 + L2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b80993d-151d-4fa7-81e6-823eb0658107",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from  sklearn.linear_model import LinearRegression, Lasso,Ridge\n",
    "from  sklearn.model_selection import train_test_split\n",
    "from  sklearn.metrics import mean_squared_error,r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c536c4db-5f7d-4441-9551-8ab8cf82dcfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Synthetic Data Generation\n",
    "np.random.seed(42)\n",
    "X = np.random.randn(100,10)\n",
    "y = X[:,0]*5 + np.random.randn(100)*5 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cf4b01e9-dc0a-44ec-a22b-9c3f0eb34f2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression MSE: 29.512824624014975\n",
      "Linear Regression R2 Score: 0.23523598629552778\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=42)\n",
    "\n",
    "#Without regularization\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train,y_train)\n",
    "\n",
    "print(\"Linear Regression MSE:\", mean_squared_error(y_test, lr.predict(X_test)))\n",
    "print(\"Linear Regression R2 Score:\", r2_score(y_test, lr.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "afda738c-dc47-482c-902e-55519e59e7fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge Regression MSE: 29.272298611027974\n",
      "Ridge Regression R2 Score: 0.24146872211243742\n"
     ]
    }
   ],
   "source": [
    "# With L2 regularization (Ridge)\n",
    "ridge = Ridge(alpha=1.0)  # alpha = Î»\n",
    "ridge.fit(X_train, y_train)\n",
    "print(\"Ridge Regression MSE:\", mean_squared_error(y_test, ridge.predict(X_test)))\n",
    "print(\"Ridge Regression R2 Score:\", r2_score(y_test, ridge.predict(X_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bb53341e-ed5b-407b-b871-bd982bef35c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso Regression MSE: 28.504731313528236\n",
      "Lasso Regression R2 Score: 0.24146872211243742\n",
      "Lasso selected features: 8\n"
     ]
    }
   ],
   "source": [
    "# With L1 regularization (Lasso)\n",
    "lasso = Lasso(alpha=0.1)\n",
    "lasso.fit(X_train, y_train)\n",
    "print(\"Lasso Regression MSE:\", mean_squared_error(y_test, lasso.predict(X_test)))\n",
    "print(\"Lasso Regression R2 Score:\", r2_score(y_test, ridge.predict(X_test)))\n",
    "print(\"Lasso selected features:\", np.sum(lasso.coef_ != 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05a35ac7-e240-4fe7-9652-bdd721d44978",
   "metadata": {},
   "source": [
    "Summary:\n",
    "Linear Regression might overfit.\n",
    "Ridge reduces overfitting by penalizing large weights.\n",
    "Lasso goes further, eliminating irrelevant features by shrinking them to zero.\n",
    "\n",
    "Use Cases:\n",
    "L1 (Lasso): High-dimensional data, when you want feature selection.\n",
    "L2 (Ridge): When all features are useful but you want to reduce overfitting.\n",
    "ElasticNet: When you want the benefits of both."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e823ef5-790b-46fd-a31f-07ebfa735b76",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
